{% extends "index_template.html" %}
{% block content %}
    <section class="section">
        <div class="container">
            <div class="columns">
                
                <div class="column is-12">
                    
                    
                    
                    
<div class="content">
    <h1 id="leaderboard-guidelines">Leaderboard Guidelines</h1>

<p class="is-size-5"> Every dataset in TDC is a benchmark, and we provide training, validation, and test sets for it, together with data splits and performance evaluation metrics. </p>

<p class="is-size-5">To participate in the leaderboard for a specific benchmark, follow these steps: </p>
<ol>
    <li><p class="is-size-5">Use the TDC benchmark data loader to retrieve the benchmark.</p></li>
    <li><p class="is-size-5">Use training and/or validation set to train your model.</p></li>
    <li><p class="is-size-5">Use the TDC model evaluator to calculate the performance of your model on the test set.</p></li>
    <li><p class="is-size-5">Submit the test set performance to a TDC leaderboard.</p></li>
</ol>

<p class="is-size-5">Below we provide detailed instructions on how to participate in TDC leaderboards. </p>

<p class="is-size-5">As many datasets share a therapeutics theme, we organize benchmarks into meaningfully defined groups, which we refer to as <b>benchmark groups</b>. Datasets and tasks within a benchmark group are carefully curated and centered around a theme (for example, TDC contains a benchmark group to support ML predictions of the ADMET properties). While every benchmark group consists of multiple benchmarks, it is possible to separately submit results for each benchmark in the group.</p>

<div class="column is-12">
    <hr />
</div>

<h2 id="step-by-step-instructions">Step-by-step Instructions</h2>

<p class="is-size-5"> TDC provides a programmatic framework to access the benchmarks and use them for model evaluation.</p>

<h4 id="step-1-train-your-model-using-a-tdc-benchmarkgroup">Step 1: Train your model using a TDC BenchmarkGroup</h4>

<p class="is-size-5"> Suppose you want to evaluate your model on the <code>Caco2_Wang</code> benchmark that belongs to the <code>ADMET_Group</code> benchmark group. Take the following code and replace the commented line block with the code to train your model. The <code>train</code>, <code>valid</code>, <code>test</code> variables contain the split of the benchmark dataset. </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc_ml.benchmark_group</span> <span class="kn">import</span> <span class="n">admet_group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">admet_group</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="s">'data/'</span><span class="p">)</span>
<span class="n">predictions_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>
    <span class="n">benchmark</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'Caco2_Wang'</span><span class="p">)</span> 
    <span class="c1"># all benchmark names in a benchmark group are stored in group.dataset_names
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span>
    <span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'train_val'</span><span class="p">],</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'test'</span><span class="p">]</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get_train_valid_split</span><span class="p">(</span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">name</span><span class="p">,</span> <span class="n">split_type</span> <span class="o">=</span> <span class="s">'default'</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
    
        <span class="c1"># --------------------------------------------- # 
</span>        <span class="c1">#  Train your model using train, valid, test    #
</span>        <span class="c1">#  Save test prediction in y_pred_test variable #
</span>        <span class="c1"># --------------------------------------------- #
</span>        
    <span class="n">predictions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_test</span>
    <span class="n">predictions_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">evaluate_many</span><span class="p">(</span><span class="n">predictions_list</span><span class="p">)</span>
<span class="c1"># {'caco2_wang': [6.328, 0.101]}
</span></code></pre></div></div>

<p class="is-size-5"> The output <code>results</code> is a dictionary storing average values and standard deviations of each performance metric achieved by your model on the <code>Caco2_Wang</code> benchmark. </p>

<h4 id="step-2-submit-results-of-your-model-to-a-tdc-leaderboard">Step 2: Submit results of your model to a TDC Leaderboard</h4>

<!-- <p class="is-size-5"> We invite submissions to any one or multiple benchmarks in a group. To be included in the leaderboard, please fill out <b><a href="https://forms.gle/HYupGaV7WDuutbr9A">THIS FORM</a></b>, include results of your model and provide a brief summary about your model (e.g., the number of parameters and hardware details).</p> -->
<p class="is-size-5"> We invite submissions to any one or multiple benchmarks in a group. To be included in the leaderboard, please follow <b><a href="https://github.com/mims-harvard/tdc2website-flask/blob/main/README.md">THE LEADERBOARD ENTRY PROCESS</a></b>, include results of your model and provide a brief summary about your model (e.g., the number of parameters and hardware details).</p>

<div class="column is-12">
    <hr />
</div>

<h2 id="further-details-about-benchmark-groups-in-tdc">Further Details about Benchmark Groups in TDC</h2>

<p class="is-size-5"> The <code>BenchmarkGroup</code> class is a wrapper class that provides utility functions for benchmarking. For each benchmark, TDC provides a separate <code>test</code> set and a <code>train_val</code> set. </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc_ml.benchmark_group</span> <span class="kn">import</span> <span class="n">admet_group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">admet_group</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="s">'data/'</span><span class="p">)</span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'Caco2_Wang'</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">name</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span>
<span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'train_val'</span><span class="p">],</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'test'</span><span class="p">]</span>

<span class="c1">## --- train your model --- ##
</span>
<span class="n">predictions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span>
<span class="n">group</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="c1"># {'caco2_wang': {'mae': 0.234}}
</span></code></pre></div></div>

<p class="is-size-5"> You can use <code>train_val</code> to construct training and validation sets as you see best fit. For example, you can (1) construct a customized training and validation set using the <code>train_val</code> or (2) use a <a href="https://tdcommons.ai/functions/data_split">TDC utility function</a> to get data splits for different random seeds: </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get_train_valid_split</span><span class="p">(</span><span class="n">benchmark</span> <span class="o">=</span> <span class="s">'Caco2_Wang'</span><span class="p">,</span> <span class="n">split_type</span> <span class="o">=</span> <span class="s">'default'</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p class="is-size-5"> Importantly, you must evaluate your model on the test set as specified by TDC to ensure fair comparison of models. To promote robust measurement of model performance, TDC requires at minimum five independent runs of the model to calculate average performance and standard deviation. Following is an example showing how to obtain five different train and validation splits: </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc_ml.benchmark_group</span> <span class="kn">import</span> <span class="n">admet_group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">admet_group</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="s">'data/'</span><span class="p">)</span>
<span class="n">predictions_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>

    <span class="n">benchmark</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'Caco2_Wang'</span><span class="p">)</span>
    
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span>
    <span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'train_val'</span><span class="p">],</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'test'</span><span class="p">]</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get_train_valid_split</span><span class="p">(</span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">name</span><span class="p">,</span> <span class="n">split_type</span> <span class="o">=</span> <span class="s">'default'</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
    
    <span class="c1">## --- train your model --- ##
</span>        
    <span class="n">predictions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_test</span>
    <span class="n">predictions_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="n">group</span><span class="p">.</span><span class="n">evaluate_many</span><span class="p">(</span><span class="n">predictions_list</span><span class="p">)</span>
<span class="c1"># {'caco2_wang': [6.328, 0.101]}
</span></code></pre></div></div>

<p class="is-size-5"> You can get a list of benchmarks included in the benchmark group as follows: </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="n">names</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="n">retrieve_benchmark_names</span><span class="p">(</span><span class="s">'ADMET_Group'</span><span class="p">)</span>
<span class="c1"># ['caco2_wang', 'hia_hou', ....]
</span></code></pre></div></div>
<p class="is-size-5"> Alternatively, the same can be achieved via: </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc_ml.benchmark_group</span> <span class="kn">import</span> <span class="n">admet_group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">admet_group</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="s">'data/'</span><span class="p">)</span>
<span class="n">group</span><span class="p">.</span><span class="n">dataset_names</span>
<span class="c1"># ['caco2_wang', 'hia_hou', ....]
</span></code></pre></div></div>

<p class="is-size-5"> For every benchmark group, we provide multiple benchmarks that all instantiate the same learning task. We encourage you to submit results for the entire benchmark group; however, we also accept submissions reporting performance on just one benchmark in the group. To access all benchmarks in a group, TDC provides the following helper function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tdc_ml.benchmark_group</span> <span class="kn">import</span> <span class="n">admet_group</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">admet_group</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="s">'data/'</span><span class="p">)</span>
<span class="n">predictions_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">benchmark</span> <span class="ow">in</span> <span class="n">group</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span>
        <span class="n">train_val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'train_val'</span><span class="p">],</span> <span class="n">benchmark</span><span class="p">[</span><span class="s">'test'</span><span class="p">]</span>
        <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">get_train_valid_split</span><span class="p">(</span><span class="n">benchmark</span> <span class="o">=</span> <span class="n">name</span><span class="p">,</span> <span class="n">split_type</span> <span class="o">=</span> <span class="s">'default'</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
        <span class="c1">## --- train your model --- ##
</span>        <span class="n">predictions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_test</span>
    <span class="n">predictions_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="n">group</span><span class="p">.</span><span class="n">evaluate_many</span><span class="p">(</span><span class="n">predictions_list</span><span class="p">)</span>
<span class="c1"># {'caco2_wang': [6.328, 0.101], 'hia_hou': [0.5, 0.01], ...}
</span></code></pre></div></div>
<div class="column is-12">
    <hr />
</div>

<h2 id="the-fair-guiding-principles">The FAIR Guiding Principles</h2>

<p class="is-size-5">ML tools have become essential for research. TDC leaderboards keep track of ML tools across the entire range of therapeutics. To improve the findability, accessibility, interoperability, and reuse of ML tools, we apply <a href="https://github.com/force11/FAIR4RS">FAIR4RS principles and implementation guidelines</a> to all software and ML tools included in TDC leaderboards.</p>

<p class="is-size-5">We strongly believe that software and ML tools should be open and adhere to FAIR principles to encourage repeatability, reproducibility, and reuse. TDC follows the FAIR guidelines for both <a href="https://www.nature.com/articles/sdata201618%22"> datasets </a> as well as <a href="https://content.iospress.com/articles/data-science/ds190026#ref001">ML tools and data functions</a>. </p>

<div class="column is-12">
    <hr />
</div>

<p class="is-size-3 has-text-centered"> <strong>Start Exploring Groups of Leaderboards in TDC</strong> </p>

<div class="container">
        <div class="columns is-vcentered is-size-5">
            <div class="column is-4 has-text-centered"> <a href="/benchmark/admet_group/overview" class="box has-background-info has-text-white">ADMET Group</a></div>
            <div class="column is-4 has-text-centered"> <a href="/benchmark/drugcombo_group/overview" class="box has-background-info has-text-white">Drug Combination Group</a></div>
            <div class="column is-4 has-text-centered"> <a href="/benchmark/docking_group/overview" class="box has-background-info has-text-white">Docking Group</a></div>
            <div class="column is-4 has-text-centered"> <a href="/benchmark/scdti_group/overview" class="box has-background-info has-text-white">Single-cell DTI Group</a></div>
            <div class="column is-4 has-text-centered"> <a href="/benchmark/proteinpeptide_group/overview" class="box has-background-info has-text-white">Protein-Peptide Binding Affinity Group</a></div>
            <div class="column is-4 has-text-centered"> <a href="/benchmark/counterfactual_group/overview" class="box has-background-info has-text-white">Counterfactual Prediction Group</a></div>
        </div>
</div>


</div>
                </div>
                
            </div>
        </div>
    </section>
{% endblock %} 